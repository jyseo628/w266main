{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(prefix=''):\n",
    "    train_data = pd.read_csv('../../data/{}train_data.csv'.format(prefix), encoding='ISO-8859-1', keep_default_na=False)\n",
    "    dev_data = pd.read_csv('../../data/{}dev_data.csv'.format(prefix), encoding='ISO-8859-1', keep_default_na=False)\n",
    "    test_data = pd.read_csv('../../data/{}test_data.csv'.format(prefix), encoding='ISO-8859-1', keep_default_na=False)\n",
    "    return train_data, dev_data, test_data\n",
    "\n",
    "train_data, dev_data, test_data = read_csv('fully_cleansed_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can someon fix twitter pleas smell of aquat ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>just walk up stop stori escal at peachtre cent...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ye there proof two lovebird go to enjoy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im so sorri youtub video accident delet danc v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>want to go home now come back on thursday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mmmm shamrat arriv</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>go round aunit in pool x</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cheer buddi will good see last night bit of ba...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sorri to hear will come kick ass in day if wan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>think time to retir saab</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  can someon fix twitter pleas smell of aquat ma...          0\n",
       "1  just walk up stop stori escal at peachtre cent...          0\n",
       "2            ye there proof two lovebird go to enjoy          4\n",
       "3  im so sorri youtub video accident delet danc v...          0\n",
       "4          want to go home now come back on thursday          0\n",
       "5                                 mmmm shamrat arriv          4\n",
       "6                           go round aunit in pool x          4\n",
       "7  cheer buddi will good see last night bit of ba...          4\n",
       "8  sorri to hear will come kick ass in day if wan...          0\n",
       "9                           think time to retir saab          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sure thing should start with ustream amp blip ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thank for video for alo girl tonight enjoy ver...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>so sad didnt camera while burn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not nice night to out on tile drive safe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>look for anyon gd to help with logo design pro...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weve got holiday rain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>workout wick hard alway limp when finish</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>damn u den just threw away</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ye isnt interest own mom made day about can te...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cant wait to get your best ohh def drove n hal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  sure thing should start with ustream amp blip ...          4\n",
       "1  thank for video for alo girl tonight enjoy ver...          4\n",
       "2                     so sad didnt camera while burn          0\n",
       "3           not nice night to out on tile drive safe          0\n",
       "4  look for anyon gd to help with logo design pro...          4\n",
       "5                              weve got holiday rain          0\n",
       "6           workout wick hard alway limp when finish          4\n",
       "7                         damn u den just threw away          0\n",
       "8  ye isnt interest own mom made day about can te...          4\n",
       "9  cant wait to get your best ohh def drove n hal...          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rows in train data: 512240\n",
      "Negative rows in train data: 511760\n"
     ]
    }
   ],
   "source": [
    "print('Positive rows in train data: {}'.format(train_data[ train_data['sentiment'] == 4]['sentiment'].size))\n",
    "print('Negative rows in train data: {}'.format(train_data[ train_data['sentiment'] == 0]['sentiment'].size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Baseline NB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024000,) (1024000,)\n",
      "(256000,) (256000,)\n",
      "(320000,) (320000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = train_data['text'].values, train_data['sentiment'].values\n",
    "X_dev, Y_dev = dev_data['text'].values, dev_data['sentiment'].values\n",
    "X_test, Y_test = test_data['text'].values, test_data['sentiment'].values\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_dev.shape, Y_dev.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the vocabulary is 675688\n",
      "(1024000, 675688) (1024000,)\n"
     ]
    }
   ],
   "source": [
    "# transform text data using Tfidf vectorizer\n",
    "tfidf = TfidfVectorizer(strip_accents='ascii', ngram_range=(1,2), min_df=2, \n",
    "                        use_idf=False, sublinear_tf=True)\n",
    "tfidf_train = tfidf.fit_transform(X_train)\n",
    "tfidf_test = tfidf.transform(X_test)\n",
    "train_tfidf_names = tfidf.get_feature_names()\n",
    "print(\"Size of the vocabulary is\", tfidf_train.shape[1])\n",
    "print(tfidf_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 0-weight terms using logistic regression\n",
    "logreg = LogisticRegression(penalty='l1', tol=0.01, C=1)\n",
    "logreg.fit(tfidf_train, Y_train)\n",
    "nonzero_feature_index = np.array(np.nonzero(logreg.coef_[0])[0])\n",
    "features = [train_tfidf_names[int(w)] for w in nonzero_feature_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the vocabulary is 18932\n",
      "(1024000, 18932) (1024000,)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(strip_accents='ascii', ngram_range=(1,2), min_df=2, \n",
    "                        use_idf=False, sublinear_tf=True, max_features=len(features))\n",
    "tfidf_train = tfidf.fit_transform(X_train)\n",
    "tfidf_test = tfidf.transform(X_test)\n",
    "train_tfidf_names = tfidf.get_feature_names()\n",
    "print(\"Size of the vocabulary is\", tfidf_train.shape[1])\n",
    "print(tfidf_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.38 s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.79      0.77    152701\n",
      "          4       0.80      0.77      0.78    167299\n",
      "\n",
      "avg / total       0.78      0.78      0.78    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB(alpha=1)\n",
    "\n",
    "start = time.time()\n",
    "bnb.fit(tfidf_train, Y_train)\n",
    "end = time.time()\n",
    "print(\"Elapsed time:\", \"{:.2f}\".format(end - start), \"s\")\n",
    "\n",
    "predicted = bnb.predict(tfidf_test)\n",
    "print (classification_report(predicted, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.27 s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.78      0.79    162671\n",
      "          4       0.78      0.79      0.78    157329\n",
      "\n",
      "avg / total       0.79      0.79      0.79    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1)\n",
    "\n",
    "start = time.time()\n",
    "mnb.fit(tfidf_train, Y_train)\n",
    "end = time.time()\n",
    "print(\"Elapsed time:\", \"{:.2f}\".format(end - start), \"s\")\n",
    "\n",
    "predicted = mnb.predict(tfidf_test)\n",
    "print (classification_report(predicted, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 positive words: ['for', 'good', 'im', 'in', 'just', 'love', 'of', 'on', 'thank', 'with']\n",
      "Top 10 negative words: ['but', 'for', 'go', 'im', 'in', 'just', 'not', 'of', 'on', 'so']\n"
     ]
    }
   ],
   "source": [
    "log_prob = mnb.feature_log_prob_\n",
    "prob = np.exp(log_prob)\n",
    "sorted_prob = np.copy(prob)\n",
    "sorted_prob.sort(axis=1)\n",
    "feature_names = tfidf.get_feature_names()\n",
    "# Save 20 features in a list\n",
    "positive_index = []\n",
    "negative_index = []\n",
    "positive_feature_list = []\n",
    "negative_feature_list = []\n",
    "for i in range(len(prob[1])):\n",
    "    if prob[1][i] in sorted_prob[1][-11:-1]:\n",
    "        positive_index.append(i)\n",
    "for ind in positive_index:\n",
    "    positive_feature_list.append(feature_names[ind])\n",
    "    \n",
    "for i in range(len(prob[0])):\n",
    "    if prob[0][i] in sorted_prob[0][-11:-1]:\n",
    "        negative_index.append(i)\n",
    "for ind in negative_index:\n",
    "    negative_feature_list.append(feature_names[ind])\n",
    "    \n",
    "print(\"Top 10 positive words:\", positive_feature_list)\n",
    "print(\"Top 10 negative words:\", negative_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
