{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cnn_models' from '/home/jerrysong/w266-Final-project/jerry/cnn_models.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Characters level ConvNet paper: https://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classification.pdf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cnn_models as models\n",
    "import importlib\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Concatenate, ThresholdedReLU, MaxPooling1D, Flatten, Dropout, ReLU, Activation\n",
    "from keras.layers import Convolution1D\n",
    "from keras.layers import Embedding\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/no_tags_lower_train_data.csv', encoding='ISO-8859-1', keep_default_na=False)\n",
    "test_data = pd.read_csv('../data/no_tags_lower_test_data.csv', encoding='ISO-8859-1', keep_default_na=False)\n",
    "dev_data = pd.read_csv('../data/no_tags_lower_dev_data.csv', encoding='ISO-8859-1', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!': 41,\n",
       " '\"': 45,\n",
       " '#': 51,\n",
       " '$': 52,\n",
       " '%': 53,\n",
       " '&': 55,\n",
       " \"'\": 44,\n",
       " '(': 64,\n",
       " ')': 65,\n",
       " '*': 56,\n",
       " '+': 59,\n",
       " ',': 38,\n",
       " '-': 60,\n",
       " '.': 40,\n",
       " '/': 46,\n",
       " '0': 27,\n",
       " '1': 28,\n",
       " '2': 29,\n",
       " '3': 30,\n",
       " '4': 31,\n",
       " '5': 32,\n",
       " '6': 33,\n",
       " '7': 34,\n",
       " '8': 35,\n",
       " '9': 36,\n",
       " ':': 43,\n",
       " ';': 39,\n",
       " '<': 62,\n",
       " '=': 61,\n",
       " '>': 63,\n",
       " '?': 42,\n",
       " '@': 50,\n",
       " '[': 66,\n",
       " '\\\\': 47,\n",
       " ']': 67,\n",
       " '^': 54,\n",
       " '_': 49,\n",
       " '`': 58,\n",
       " 'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '{': 68,\n",
       " '|': 48,\n",
       " '}': 69,\n",
       " '~': 57}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = 'abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:\\'\"/\\\\|_@#$%^&*~`+-=<>()[]{}'\n",
    "alphabet_size = len(alphabet)\n",
    "alphabet_index = {alphabet[i]: i + 1 for i in range(alphabet_size)}\n",
    "alphabet_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max input size is: 1390\n"
     ]
    }
   ],
   "source": [
    "max_input_size = max(len(row['text']) for _, row in train_data.iterrows())\n",
    "print('The max input size is: ' + str(max_input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average input size is: 68.3684013671875\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean \n",
    "average_input_size = mean(len(row['text']) for _, row in train_data.iterrows())\n",
    "print('The average input size is: ' + str(average_input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = models.text_to_padding(train_data, alphabet_index, input_length)\n",
    "X_test = models.text_to_padding(test_data, alphabet_index, input_length)\n",
    "X_dev = models.text_to_padding(dev_data, alphabet_index, input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tranin: (1024000, 500)\n",
      "test: (320000, 500)\n",
      "dev: (256000, 500)\n"
     ]
    }
   ],
   "source": [
    "print('tranin: ' + str(X_train.shape))\n",
    "print('test: ' + str(X_test.shape))\n",
    "print('dev: ' + str(X_dev.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = pd.get_dummies(train_data['sentiment']).values\n",
    "Y_test = pd.get_dummies(test_data['sentiment']).values\n",
    "Y_dev = pd.get_dummies(dev_data['sentiment']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tranin: (1024000, 2)\n",
      "test: (320000, 2)\n",
      "dev: (256000, 2)\n"
     ]
    }
   ],
   "source": [
    "print('tranin: ' + str(Y_train.shape))\n",
    "print('test: ' + str(Y_test.shape))\n",
    "print('dev: ' + str(Y_dev.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 128)          8960      \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 494, 256)          229632    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 164, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 158, 256)          459008    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 52, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 50, 256)           196864    \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 48, 256)           196864    \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 46, 256)           196864    \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 44, 256)           196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 14, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3584)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              3671040   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 6,207,746\n",
      "Trainable params: 6,207,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'epochs': 4,\n",
    "    'batch_size': 256,\n",
    "    'alphabet_size': alphabet_size + 1, # All nonalphabet characters are seen as the same character\n",
    "    'embedding_size': 128,\n",
    "    'input_length': input_length,\n",
    "    'filters': [256, 256, 256, 256, 256, 256],\n",
    "    'kernal_size': [7, 7, 3, 3, 3, 3],\n",
    "    'pool_size': [3, 3, None, None, None, 3],\n",
    "    'fully_connected_dim': [1024, 1024],\n",
    "    'dropout_rate': [0.5, 0.5],\n",
    "    'loss': 'binary_crossentropy',\n",
    "    'activation': 'sigmoid',\n",
    "    'lr': 0.0001,\n",
    "}\n",
    "\n",
    "model = models.get_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1024000 samples, validate on 256000 samples\n",
      "Epoch 1/4\n",
      "1024000/1024000 [==============================] - 907s 886us/step - loss: 0.5113 - acc: 0.7416 - val_loss: 0.4614 - val_acc: 0.7802\n",
      "Epoch 2/4\n",
      "1024000/1024000 [==============================] - 865s 845us/step - loss: 0.4305 - acc: 0.8018 - val_loss: 0.4194 - val_acc: 0.8068\n",
      "Epoch 3/4\n",
      "1024000/1024000 [==============================] - 863s 843us/step - loss: 0.3984 - acc: 0.8203 - val_loss: 0.4023 - val_acc: 0.8174\n",
      "Epoch 4/4\n",
      "1024000/1024000 [==============================] - 861s 841us/step - loss: 0.3744 - acc: 0.8336 - val_loss: 0.3952 - val_acc: 0.8213\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, \n",
    "    Y_train, \n",
    "    validation_data=[X_dev, Y_dev], \n",
    "    epochs=params['epochs'], \n",
    "    batch_size=params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320000/320000 [==============================] - 72s 226us/step\n",
      "score: 0.39531848\n",
      "acc: 0.82130313\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test, Y_test, batch_size=params['batch_size'])\n",
    "print(\"score: %.8f\" % (score))\n",
    "print(\"acc: %.8f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
