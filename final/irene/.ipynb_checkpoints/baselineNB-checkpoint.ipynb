{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jooyeon_seo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, CuDNNLSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keeping the necessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/fully_cleansed_train_data.csv'.format(prefix), encoding='ISO-8859-1', keep_default_na=False)\n",
    "test_data = pd.read_csv('../data/fully_cleansed_test_data.csv'.format(prefix), encoding='ISO-8859-1', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>551940</th>\n",
       "      <td>@DonnieWahlberg Haha!  Would love to, but sadl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085039</th>\n",
       "      <td>@taytaymonay hey girrl glad to have you on her...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170478</th>\n",
       "      <td>@steph_davies It's only 9:30pm.  I'll wait for...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181071</th>\n",
       "      <td>@successforall Couldn't agree with you more!</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430836</th>\n",
       "      <td>@jamesheart24 I am great.. 'Revising' for my l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496476</th>\n",
       "      <td>@LLPH a wife away from her husband?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36314</th>\n",
       "      <td>hoping to go to Nyc or L.A soon i miss it there</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461189</th>\n",
       "      <td>anyone know of an app or program that helps me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445099</th>\n",
       "      <td>@raquelaberakiki Hahaha, paid or not, I'm sure...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9629</th>\n",
       "      <td>So sleepy. Friday night was ruined by a stupid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  sentiment\n",
       "551940   @DonnieWahlberg Haha!  Would love to, but sadl...          0\n",
       "1085039  @taytaymonay hey girrl glad to have you on her...          4\n",
       "1170478  @steph_davies It's only 9:30pm.  I'll wait for...          4\n",
       "1181071      @successforall Couldn't agree with you more!           4\n",
       "430836   @jamesheart24 I am great.. 'Revising' for my l...          0\n",
       "1496476               @LLPH a wife away from her husband?           4\n",
       "36314     hoping to go to Nyc or L.A soon i miss it there           0\n",
       "461189   anyone know of an app or program that helps me...          0\n",
       "1445099  @raquelaberakiki Hahaha, paid or not, I'm sure...          4\n",
       "9629     So sleepy. Friday night was ruined by a stupid...          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_data[test_data['sentiment'].isin([0, 4])]\n",
    "test_data['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@richardebaker no. it is too big. I'm quite ha...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fuck this economy. I hate aig and their non lo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jquery is my new best friend.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Loves twitter</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>how can you not love Obama? he makes jokes abo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  @stellargirl I loooooooovvvvvveee my Kindle2. ...          4\n",
       "1  Reading my kindle2...  Love it... Lee childs i...          4\n",
       "2  Ok, first assesment of the #kindle2 ...it fuck...          4\n",
       "3  @kenburbary You'll love your Kindle2. I've had...          4\n",
       "4  @mikefish  Fair enough. But i have the Kindle2...          4\n",
       "5  @richardebaker no. it is too big. I'm quite ha...          4\n",
       "6  Fuck this economy. I hate aig and their non lo...          0\n",
       "7                      Jquery is my new best friend.          4\n",
       "8                                      Loves twitter          4\n",
       "9  how can you not love Obama? he makes jokes abo...          4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rows in train data: 800000\n",
      "Negative rows in train data: 800000\n"
     ]
    }
   ],
   "source": [
    "print('Positive rows in train data: {}'.format(train_data[ train_data['sentiment'] == 4]['sentiment'].size))\n",
    "print('Negative rows in train data: {}'.format(train_data[ train_data['sentiment'] == 0]['sentiment'].size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Baseline NB model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000,) (1600000,)\n",
      "(359,) (359,)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = train_data['text'].values, train_data['sentiment'].values\n",
    "X_test, Y_test = test_data['text'].values, test_data['sentiment'].values\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive train data:  800000 , negative train data:  800000\n",
      "positive test data:  182 , negative test data:  177\n"
     ]
    }
   ],
   "source": [
    "print ('positive train data: ', len(np.where(Y_train==4)[0]), \n",
    "       ', negative train data: ', len(np.where(Y_train==0)[0]))\n",
    "print ('positive test data: ', len(np.where(Y_test==4)[0]), \n",
    "       ', negative test data: ', len(np.where(Y_test==0)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the vocabulary is 10000\n",
      "(1600000, 10000) (1600000,)\n"
     ]
    }
   ],
   "source": [
    "# transform text data using Tfidf vectorizer\n",
    "max_features = 10000\n",
    "tfidf = TfidfVectorizer(strip_accents='ascii', ngram_range=(1,1), min_df=2, \n",
    "                        stop_words='english', use_idf=False, sublinear_tf=True, max_features=max_features)\n",
    "tfidf_train = tfidf.fit_transform(X_train)\n",
    "tfidf_test = tfidf.transform(X_test)\n",
    "train_tfidf_names = tfidf.get_feature_names()\n",
    "print(\"Size of the vocabulary is\", tfidf_train.shape[1])\n",
    "print(tfidf_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 0-weight terms using logistic regression\n",
    "logreg = LogisticRegression(penalty='l1', tol=0.01, C=10)\n",
    "logreg.fit(tfidf_train, Y_train)\n",
    "nonzero_feature_index = np.array(np.nonzero(logreg.coef_[0])[0])\n",
    "features = [train_tfidf_names[int(w)] for w in nonzero_feature_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the vocabulary is 9773\n",
      "(1600000, 9773) (1600000,)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(use_idf=False, sublinear_tf=True, vocabulary=list(set(features)))\n",
    "tfidf_train = tfidf.fit_transform(X_train)\n",
    "tfidf_test = tfidf.transform(X_test)\n",
    "print(\"Size of the vocabulary is\", tfidf_train.shape[1])\n",
    "print(tfidf_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.81      0.81       179\n",
      "          4       0.81      0.82      0.82       180\n",
      "\n",
      "avg / total       0.82      0.82      0.82       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB(alpha=0.01)\n",
    "bnb.fit(tfidf_train, Y_train)\n",
    "predicted = bnb.predict(tfidf_test)\n",
    "print (classification_report(predicted, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 positive words: ['good', 'thanks', 'today', 'love', 'like', 'going', 'lol', 'com', 'day', 'http']\n",
      "Top 10 negative words: ['want', 'work', 'today', 'really', 'like', 'going', 'got', 'miss', 'don', 'day']\n"
     ]
    }
   ],
   "source": [
    "log_prob = bnb.feature_log_prob_\n",
    "prob = np.exp(log_prob)\n",
    "sorted_prob = np.copy(prob)\n",
    "sorted_prob.sort(axis=1)\n",
    "feature_names = tfidf.get_feature_names()\n",
    "# Save 20 features in a list\n",
    "positive_index = []\n",
    "negative_index = []\n",
    "positive_feature_list = []\n",
    "negative_feature_list = []\n",
    "for i in range(len(prob[1])):\n",
    "    if prob[1][i] in sorted_prob[1][-11:-1]:\n",
    "        positive_index.append(i)\n",
    "for ind in positive_index:\n",
    "    positive_feature_list.append(feature_names[ind])\n",
    "    \n",
    "for i in range(len(prob[0])):\n",
    "    if prob[0][i] in sorted_prob[0][-11:-1]:\n",
    "        negative_index.append(i)\n",
    "for ind in negative_index:\n",
    "    negative_feature_list.append(feature_names[ind])\n",
    "    \n",
    "print(\"Top 10 positive words:\", positive_feature_list)\n",
    "print(\"Top 10 negative words:\", negative_feature_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
